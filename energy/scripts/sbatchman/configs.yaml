variables:
  nodes: [2, 4, 8, 16, 32]
  channels: [2, 4, 8, 16, 32]
  protocols_1: ["Simple", "LL",  "LL128"]
  protocols_2: ["Simple"]
  algorithms_1: [Ring, Tree]
  algorithms_2: [ColletDirect, Collnet, NVLS, NVLSTree] 
  threads: [64, 128, 256, 512]
  partition_leonardo: ["boost_usr_prod"]
  partition_lumi: [dev-g]

  ################ TEST #####################
  # nodes: [2]
  # channels: [2]
  # protocols_1: ["Simple"]
  # protocols_2: ["Simple"]
  # threads: [64]
  # partition_leonardo: [boost_usr_prod]
  # partition_lumi: [dev-g]
  # algorithms_1: [Ring]
  # algorithms_2: [ColletDirect] 
  #####################################

  
leonardo:
  scheduler: slurm

  default_conf:
    account: "IscrC_OMG-25"
    exclusive: true
    partition: debug
    gpus: 4
    cpus_per_task: 1
    tasks_per_node: 4
    time: "00:20:00"

  configs:
    ########################################### ALL TO ALL ###########################################
    - name: "a2a_n{nodes}_prot{protocols_1}_ch{channels}_th{threads}_{partition_leonardo}"
      account: "IscrC_OMG-25"
      nodes: "{nodes}"
      exclusive: true
      partition: "{partition_leonardo}"
      time: "00:20:00"
      modules: ["gcc/", "cuda/12.2", "openmpi/", "nvhpc/", "nccl/"]
      env:
        - "NCCL_PROTO={protocols_1}"
        - "NCCL_MIN_CTAS={channels}"
        - "NCCL_MAX_CTAS={channels}"
        - "NCCL_NTHREADS={threads}"
    #####################################################################################################

    ####### all reduce config for {Simple, LL, LL128} x {Ring, Tree}. Only for Ring and Tree alg we can use all the protocols ######
    # - name: "ar_n{nodes}_alg{algorithms_1}_prot{protocols_1}_ch{channels}_th{threads}_{partition_leonardo}"
    #   nodes: "{nodes}"
    #   exclusive: true
    #   partition: "{partition_leonardo}"
    #   time: "00:20:00"
    #   modules: ["gcc/", "cuda/12.2", "openmpi/", "nvhpc/", "nccl/"]
    #   env:
    #     - "NCCL_AGLO={algorithms_1}"
    #     - "NCCL_PROTO={protocols_1}"
    #     - "NCCL_MIN_CTAS={channels}"
    #     - "NCCL_MAX_CTAS={channels}"
    #     - "NCCL_NTHREADS={threads}"
    ##########################################################

    ###### all reduce with Simple protocol works with all algorithm ######
    # - name: "ar_n{nodes}_alg{algorithms_2}_prot{protocols_2}_ch{channels}_th{threads}_{partition_leonardo}"
    #   nodes: "{nodes}"
    #   exclusive: true
    #   partition: "{partition_leonardo}"
    #   time: "00:20:00"
    #   modules: ["gcc/", "cuda/12.2", "openmpi/", "nvhpc/", "nccl/"]
    #   env:
    #     - "NCCL_AGLO={algorithms_2}"
    #     - "NCCL_PROTO={protocols_2}"
    #     - "NCCL_MIN_CTAS={channels}"
    #     - "NCCL_MAX_CTAS={channels}"
    #     - "NCCL_NTHREADS={threads}"
    ##########################################################

# lumi:
#   scheduler: slurm

#   default_conf:
#     account: "project_465002469"
#     exclusive: true
#     gpus: 4
#     partition: dev-g
#     cpus_per_task: 1
#     tasks_per_node: 4
#     time: "00:20:00"

#   configs:
#     - name: "a2a_n{nodes}_prot{protocols_1}_ch{channels}_th{threads}_{partition_lumi}"
#       exclusive: true
#       nodes: "{nodes}"
#       partition: "{partition_lumi}"
#       time: "00:20:00"
#       modules: ["LUMI/25.03", "PrgEnv-cray", "craype-accel-amd-gfx90a", "rocm/6.3.4", "gcc-native"]
#       env:
#         - "NCCL_PROTO={protocols_1}"
#         - "NCCL_MIN_CTAS={channels}"
#         - "NCCL_MAX_CTAS={channels}"
#         - "NCCL_NTHREADS={threads}"
#         - "CXX=/opt/rocm-6.3.4/lib/llvm/bin/clang++"
#         - "CC=gcc"